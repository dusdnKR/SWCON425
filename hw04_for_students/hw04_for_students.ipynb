{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c351481",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/dusdnKR/SWCON425/blob/main/hw04_for_students/hw04_for_students.ipynb?hl=ko\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439f23a",
   "metadata": {},
   "source": [
    "# Homework 4: Training Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab5cefb",
   "metadata": {},
   "source": [
    "### Due Date: Monday 12/22, 23:59\n",
    "\n",
    "Homework 4 is out, it is notebook form. You need to fill in the answers in the cells and produce graphs. Everything needed for the assignment is explained in the notebook.\n",
    "\n",
    "**How to submit**\n",
    "\n",
    "You need to send the `.ipynb` file with your answers plus an `.html` file, which will serve as a backup for us in case the `.ipynb` file cannot be opened on my or the TA's computer.\n",
    "\n",
    "The homework solution should be uploaded on e-campus. You can submit it as often as you like before the deadline.\n",
    "\n",
    "**Important**\n",
    "- Please make sure that you provide an answer in each cell and place that contains the **[ your answer ]** tags.\n",
    "- The places that require your code answer are marked with \"`### YOUR CODE`\" comments.\n",
    "- Note that you may use 1 or more line of code for replacing each \"`### YOUR CODE`\" comment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aba87a",
   "metadata": {},
   "source": [
    "## Part 1: Transformers Review [30 points]\n",
    "\n",
    "In this part, you will implement key components of the GPT model architecture based on what you learned in previous lectures.  \n",
    "This will help you understand how transformers work at a fundamental level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2d06f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.9.0+cpu\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\"\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb49d73",
   "metadata": {},
   "source": [
    "### Question 1-1) `GPTDatasetV1` [5 points]\n",
    "\n",
    "Implement the dataset class that creates input-target pairs for GPT training.\n",
    "\n",
    "**HINT**\n",
    "- `input_chunk` contains tokens from `i` to `i + max_length`.\n",
    "- `target_chunk` returns the tokens immediately following `input_chunk` (shifted by one position)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23878359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = ### YOUR CODE\n",
    "            target_chunk = ### YOUR CODE\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3366ab0",
   "metadata": {},
   "source": [
    "### Question 1-2) `MultiHeadAttention` [5 points]\n",
    "\n",
    "Implement the multi-head attention mechanism which is the core component of transformers.\n",
    "\n",
    "**HINT**\n",
    "- `head_dim` is the value obtained by dividing `d_out` by `num_heads`.\n",
    "- `keys`, `queries`, and `values` are the outputs obtained by passing the input (`x`) through the `W_key`, `W_query`, and `W_value` layers, respectively.\n",
    "- In the initial shape `(b, num_tokens, d_out)` of `keys`, `queries`, and `values`, the `d_out` dimension must be split into `num_heads` and `head_dim` for per-head computation.\n",
    "- To perform computations across `num_tokens` and `head_dim`, the order of `num_heads` and `num_tokens` is swapped.\n",
    "- `attn_scores` are computed by taking the matrix multiplication (`@`) of `queries` and the transpose of `keys`.\n",
    "- `attn_weights` are obtained by applying softmax to `attn_scores` after scaling them by the square root of the dimensionality of the `keys`, `queries`, and `values`.\n",
    "- Before computing `context_vec`, dropout is applied.\n",
    "- `context_vec` is computed by taking the matrix multiplication (`@`) of `attn_weights` and `values`.\n",
    "- The final output shape must be the same as the input shape `(b, num_tokens, d_out)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1354be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = ### YOUR CODE\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = ### YOUR CODE\n",
    "        queries = ### YOUR CODE\n",
    "        values = ### YOUR CODE\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = ### YOUR CODE\n",
    "        values = ### YOUR CODE\n",
    "        queries = ### YOUR CODE\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = ### YOUR CODE\n",
    "        queries = ### YOUR CODE\n",
    "        values = ### YOUR CODE\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = ### YOUR CODE\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = ### YOUR CODE\n",
    "        attn_weights = ### YOUR CODE\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = ### YOUR CODE\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = ### YOUR CODE\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6098f",
   "metadata": {},
   "source": [
    "### Question 1-3) `LayerNorm` [5 points]\n",
    "\n",
    "Implement Layer Normalization which stabilizes training by normalizing inputs.\n",
    "\n",
    "**HINT**\n",
    "- `norm_x` is the result of normalizing `x` by subtracting the mean and dividing by the standard deviation.\n",
    "- To prevent division by zero, an `eps` value is added to the denominator.\n",
    "- The final returned value is obtained by multiplying `norm_x` by `scale` and then adding `shift`, where `scale` and `shift` are learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d166b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = ### YOUR CODE\n",
    "        return ### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828d4cf",
   "metadata": {},
   "source": [
    "### `GELU`\n",
    "\n",
    "The GELU activation function is provided for you (no implementation needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34474a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fe80e",
   "metadata": {},
   "source": [
    "### Question 1-4) `FeedForward` [5 points]\n",
    "\n",
    "Implement the Feed-Forward network that processes each position independently.\n",
    "\n",
    "**HINT**\n",
    "- `FeedForward` uses linear layers to expand the dimensionality by a factor of 4, applies GELU, and then projects the dimension back to the original size.\n",
    "- The input dimension is stored in `cfg[\"emb_dim\"]`.\n",
    "- Layers inside `nn.Sequential()` are separated by commas (`,`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f71955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            , ### YOUR CODE\n",
    "            , ### YOUR CODE\n",
    "            , ### YOUR CODE\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd415f",
   "metadata": {},
   "source": [
    "### Question 1-5) `TransformerBlock` [5 points]\n",
    "\n",
    "Implement a complete Transformer block with attention and feed-forward layers.\n",
    "\n",
    "**HINT**\n",
    "- The order of operations in `TransformerBlock` is as follows:  \n",
    "`LayerNorm(1)` → `Masked Multi-head Attention` → `Dropout` + `Shortcut Connection` →  \n",
    "`LayerNorm(2)` → `FeedForward` → `Dropout` + `Shortcut Connection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee522d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "\n",
    "        # Shortcut connection for feed-forward block\n",
    "        shortcut = x\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b604ef",
   "metadata": {},
   "source": [
    "### Question 1-6) `GPTModel` [5 points]\n",
    "\n",
    "Complete the GPT model by assembling all components together.\n",
    "\n",
    "**HINT**\n",
    "- The input `x` is the sum of the token embeddings and the positional embeddings.\n",
    "- The order of operations in `GPTModel` is as follows:  \n",
    "`Token Embedding` + `Position Embedding` → `Dropout` → `TransformerBlock` * 12 → `LayerNorm` → `Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d24d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "        x = ### YOUR CODE\n",
    "        logits = ### YOUR CODE\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d321f14",
   "metadata": {},
   "source": [
    "### Testing Your Implementation\n",
    "\n",
    "If all of the above classes are implemented correctly, you should see the output of the code below.  \n",
    "This generates text using an untrained model (<b>so the output will be random</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25192b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    GPT_CONFIG_124M = {\n",
    "        \"vocab_size\": 50257,     # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"emb_dim\": 768,          # Embedding dimension\n",
    "        \"n_heads\": 12,           # Number of attention heads\n",
    "        \"n_layers\": 12,          # Number of layers\n",
    "        \"drop_rate\": 0.1,        # Dropout rate\n",
    "        \"qkv_bias\": False        # Query-Key-Value bias\n",
    "    }\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    model = GPTModel(GPT_CONFIG_124M)\n",
    "    model.eval()  # disable dropout\n",
    "\n",
    "    start_context = \"Hello, I am\"\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    encoded = tokenizer.encode(start_context)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "    print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
    "    print(\"\\nInput text:\", start_context)\n",
    "    print(\"Encoded input text:\", encoded)\n",
    "    print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "\n",
    "    out = generate_text_simple(\n",
    "        model=model,\n",
    "        idx=encoded_tensor,\n",
    "        max_new_tokens=10,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "    )\n",
    "    decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "\n",
    "    print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
    "    print(\"\\nOutput:\", out)\n",
    "    print(\"Output length:\", len(out[0]))\n",
    "    print(\"Output text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83557fa4",
   "metadata": {},
   "source": [
    "The above result shows the output of an untrained LLM model. In the next part, you will train this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7f22d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Model Training [40 points]\n",
    "\n",
    "In this part, you will experience the complete training process of a language model.  \n",
    "You will prepare training data, implement the training loop, and monitor the model's learning progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f0df4",
   "metadata": {},
   "source": [
    "### Setup Training Configuration\n",
    "\n",
    "We'll use a smaller context length (256 instead of 1024) to reduce computational requirements while still demonstrating the training process effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf63e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 256,   # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); # disable dropout evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcba06a",
   "metadata": {},
   "source": [
    "### Prepare Training Data\n",
    "\n",
    "Download and prepare the training dataset. We'll use the short story \"`The Verdict`\" for training.\n",
    "\n",
    "**Note**: This is a very small training dataset for educational purposes. In practice, LLMs are trained on billions of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6296c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 characters:\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n",
      "\n",
      "Last 100 characters:\n",
      " it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n",
      "\n",
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "# Verify the data\n",
    "print(\"First 100 characters:\")\n",
    "print(text_data[:100])\n",
    "print(\"\\nLast 100 characters:\")\n",
    "print(text_data[-100:])\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(f\"\\nTotal characters: {total_characters}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560764f",
   "metadata": {},
   "source": [
    "### Question 2-1) Create Data Loaders [5 points]\n",
    "\n",
    "Split the data into training and validation sets, then create data loaders.\n",
    "\n",
    "**HINT**\n",
    "- Use 90% of data for training and 10% for validation.\n",
    "- `train_data` and `val_data` are split based on `split_idx`. If the split is done correctly, their lengths will be 18,431 and 2,048, respectively.\n",
    "- `train_loader` is identical to `val_loader`, but the `drop_last` and `shuffle` settings must be set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_ratio = ### YOUR CODE\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = ### YOUR CODE\n",
    "val_data = ### YOUR CODE\n",
    "\n",
    "print(f\"Training data length: {len(train_data)}\")\n",
    "print(f\"Validation data length: {len(val_data)}\")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = ### YOUR CODE\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Verify data loaders\n",
    "print(\"\\nTraining data loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation data loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187388cf",
   "metadata": {},
   "source": [
    "### Implement Loss Calculation\n",
    "\n",
    "Implement functions to calculate the cross-entropy loss for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6041c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77174bd",
   "metadata": {},
   "source": [
    "### Question 2-2) Cross Entropy [5 points]\n",
    "\n",
    "In `calc_loss_batch`, <b>what reference values</b> are used to calculate the loss?  \n",
    "Explain <b>the loss calculation method</b> and <b>the final objective</b> in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"[ your answer ]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba953ddb",
   "metadata": {},
   "source": [
    "### Setup Device and Initial Loss\n",
    "\n",
    "Check if GPU is available and calculate initial loss before training. It will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7dfa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd292d",
   "metadata": {},
   "source": [
    "### Implement Training Loop\n",
    "\n",
    "Implement the main training loop that will train your model.\n",
    "\n",
    "- In each training step: `zero gradients` → `forward pass` → `calculate loss` → `backward pass` → `update weights`\n",
    "- Track tokens seen and global step.\n",
    "- Periodically evaluate on both training and validation sets.\n",
    "- Generate sample text after each epoch to see progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e7edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Evaluate at specified frequency\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Generate sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d95628",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "Now execute the training! This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"\\nTraining completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5715a",
   "metadata": {},
   "source": [
    "### Question 2-3) Training Results [20 points]\n",
    "Please copy the output of the block above.\n",
    "\n",
    "**HINT**\n",
    "- The results include `Train loss`, `Val loss`, example generation results, and final training time for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"[ your answer ]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a472daa",
   "metadata": {},
   "source": [
    "### Question 2-4) Results Analysis [5 points]\n",
    "\n",
    "What is the writing style of the generated example sentence? What might be the reason for it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"[ your answer ]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc78be",
   "metadata": {},
   "source": [
    "### Question 2-5) Visualize Training Progress [5 points]\n",
    "\n",
    "Plot the training and validation losses to see how your model learned over time.\n",
    "\n",
    "**HINT**\n",
    "- Draw a graph using `plot()`.\n",
    "- In the legend, make `train_losses` and `val_losses` have the labels \"Training loss\" and \"Validation loss\".\n",
    "- You are free to choose any other settings as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6257807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "    ### YOUR CODE\n",
    "    ### YOUR CODE\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feadc24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Loading Pretrained Weights [30 points]\n",
    "\n",
    "In this part, you will learn how to load pretrained GPT-2 weights from OpenAI into your model.  \n",
    "This is a crucial skill as it allows you to leverage powerful pretrained models without training from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda9c24",
   "metadata": {},
   "source": [
    "### Question 3-1) Download Pretrained Weights [5 points]\n",
    "\n",
    "First, we need to download the pretrained GPT-2 weights from OpenAI.\n",
    "\n",
    "**HINT**\n",
    "- Use `download_and_load_gpt2()` to download the **124M** parameter model.\n",
    "- The weights will be saved in a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf73bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        else:\n",
    "            print(f\"{filename} already exists, skipping download.\")\n",
    "\n",
    "    # Load settings and parameters\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Load parameters from TensorFlow checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process variable names and assign to params dictionary\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip 'model/' prefix\n",
    "\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "# Download the pretrained GPT-2 124M model\n",
    "settings, params = ### YOUR CODE\n",
    "print(\"Settings:\", settings)\n",
    "print(\"\\nParameter dictionary keys:\", params.keys())\n",
    "print(\"Number of transformer blocks:\", len(params[\"blocks\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3c40b",
   "metadata": {},
   "source": [
    "### Understand Weight Structure\n",
    "\n",
    "Explore the structure of the pretrained weights to understand how they map to your model.\n",
    "\n",
    "- Examine the keys in the params dictionary.\n",
    "- Look at the shape of different weight tensors.\n",
    "- Compare with your model's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the structure of loaded parameters\n",
    "print(\"Token embedding shape:\", params[\"wte\"].shape)\n",
    "print(\"Position embedding shape:\", params[\"wpe\"].shape)\n",
    "\n",
    "# Check first transformer block structure\n",
    "print(\"\\nFirst transformer block keys:\", params[\"blocks\"][0].keys())\n",
    "\n",
    "# Check attention weights in first block\n",
    "print(\"\\nAttention weights shape:\", params[\"blocks\"][0][\"attn\"][\"c_attn\"][\"w\"].shape)\n",
    "print(\"Attention bias shape:\", params[\"blocks\"][0][\"attn\"][\"c_attn\"][\"b\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506068c",
   "metadata": {},
   "source": [
    "### Question 3-2) Implement Weight Assignment [10 points]\n",
    "\n",
    "Implement the function that assigns pretrained weights to your model.\n",
    "\n",
    "**HINT**\n",
    "- Use `.T` to transpose 2D weights when needed\n",
    "-  If you are not sure where the weights of the position embedding are stored, check the immediately preceding block.\n",
    "-  You can infer how to retrieve the weights and biases of `W_key` and `W_value` by looking at how the weights and bias of `W_query` are obtained.\n",
    "-  The ff layers and norm layers each appear twice in every block. Compare them with the code that has already been written to infer what should go in the blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights(model, params):\n",
    "    # Assign token and position embeddings\n",
    "    model.tok_emb.weight = nn.Parameter(torch.tensor(params[\"wte\"]))\n",
    "    model.pos_emb.weight = ### YOUR CODE\n",
    "\n",
    "    # Assign weights for each transformer block\n",
    "    for block_num in range(len(params[\"blocks\"])):\n",
    "        # Attention weights (c_attn contains concatenated Q, K, V)\n",
    "        q_w, k_w, v_w = np.split(params[\"blocks\"][block_num][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
    "        model.trf_blocks[block_num].att.W_query.weight = nn.Parameter(torch.tensor(q_w).T)\n",
    "        model.trf_blocks[block_num].att.W_key.weight = ### YOUR CODE\n",
    "        model.trf_blocks[block_num].att.W_value.weight = ### YOUR CODE\n",
    "\n",
    "        # Attention biases\n",
    "        q_b, k_b, v_b = np.split(params[\"blocks\"][block_num][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
    "        model.trf_blocks[block_num].att.W_query.bias = nn.Parameter(torch.tensor(q_b))\n",
    "        model.trf_blocks[block_num].att.W_key.bias = ### YOUR CODE\n",
    "        model.trf_blocks[block_num].att.W_value.bias = ### YOUR CODE\n",
    "\n",
    "        # Attention output projection\n",
    "        model.trf_blocks[block_num].att.out_proj.weight = nn.Parameter(\n",
    "            torch.tensor(params[\"blocks\"][block_num][\"attn\"][\"c_proj\"][\"w\"]).T)\n",
    "        model.trf_blocks[block_num].att.out_proj.bias = nn.Parameter(\n",
    "            torch.tensor(params[\"blocks\"][block_num][\"attn\"][\"c_proj\"][\"b\"]))\n",
    "\n",
    "        # Feed-forward weights (input projection)\n",
    "        model.trf_blocks[block_num].ff.layers[0].weight = nn.Parameter(\n",
    "            torch.tensor(params[\"blocks\"][block_num][\"mlp\"][\"c_fc\"][\"w\"]).T)\n",
    "        model.trf_blocks[block_num].ff.layers[0].bias = ### YOUR CODE\n",
    "\n",
    "        # Feed-forward weights (output projection)\n",
    "        model.trf_blocks[block_num].ff.layers[2].weight = ### YOUR CODE\n",
    "        model.trf_blocks[block_num].ff.layers[2].bias = nn.Parameter(\n",
    "            torch.tensor(params[\"blocks\"][block_num][\"mlp\"][\"c_proj\"][\"b\"]))\n",
    "\n",
    "        # Layer normalization (attention)\n",
    "        model.trf_blocks[block_num].norm1.scale = ### YOUR CODE\n",
    "        model.trf_blocks[block_num].norm1.shift = nn.Parameter(\n",
    "            torch.tensor(params[\"blocks\"][block_num][\"ln_1\"][\"b\"]))\n",
    "\n",
    "        # Layer normalization (feed-forward)\n",
    "        model.trf_blocks[block_num].norm2.scale = nn.Parameter(\n",
    "            torch.tensor(params[\"blocks\"][block_num][\"ln_2\"][\"g\"]))\n",
    "        model.trf_blocks[block_num].norm2.shift = ### YOUR CODE\n",
    "\n",
    "    # Final layer normalization\n",
    "    model.final_norm.scale = nn.Parameter(torch.tensor(params[\"g\"]))\n",
    "    model.final_norm.shift = nn.Parameter(torch.tensor(params[\"b\"]))\n",
    "\n",
    "    # Output layer (shares weights with token embedding in GPT-2)\n",
    "    model.out_head.weight = nn.Parameter(torch.tensor(params[\"wte\"]))\n",
    "\n",
    "\n",
    "# Create a new model with context_length=1024 to match GPT-2\n",
    "GPT_CONFIG_124M_PRETRAINED = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,  # Increased to match GPT-2\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True  # GPT-2 uses bias for QKV\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_pretrained = GPTModel(GPT_CONFIG_124M_PRETRAINED)\n",
    "assign_weights(model_pretrained, params)\n",
    "model_pretrained.to(device)\n",
    "model_pretrained.eval()\n",
    "\n",
    "print(\"Pretrained weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f4280",
   "metadata": {},
   "source": [
    "### Question 3-3) Generate Text with Pretrained Model [5 points]\n",
    "\n",
    "Test the pretrained model by generating text and compare it with your trained model.\n",
    "\n",
    "**HINT**\n",
    "- Use the same `generate_text_simple` function.\n",
    "- Set the `max_new_tokens` value appropriately.\n",
    "- Try different `start_contexts` to see the model's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "249faaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TEXT GENERATION WITH PRETRAINED GPT-2\n",
      "==================================================\n",
      "\n",
      "Prompt: Every effort moves you\n",
      "Generated: Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work.\n",
      "\n",
      "The second step is to understand the importance of your work.\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: Hello, I am\n",
      "Generated: Hello, I am a little bit of a fan of the original series. I have been a fan of the original series for a long time, and I have been a\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: The future of AI is\n",
      "Generated: The future of AI is uncertain. The future of AI is uncertain.\n",
      "\n",
      "The future of AI is uncertain. The future of AI is uncertain.\n",
      "\n",
      "The future of\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate text with the pretrained model\n",
    "start_contexts = [\n",
    "    \"Every effort moves you\",\n",
    "    \"Hello, I am\",\n",
    "    \"The future of AI is\"\n",
    "] ### YOUR CODE\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TEXT GENERATION WITH PRETRAINED GPT-2\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for context in start_contexts:\n",
    "    encoded = text_to_token_ids(context, tokenizer).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        token_ids = ### YOUR CODE\n",
    "    \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(f\"\\nPrompt: {context}\")\n",
    "    print(f\"Generated: {decoded_text}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd001163",
   "metadata": {},
   "source": [
    "### Question 3-4) Text Generation Results [5 points]\n",
    "\n",
    "Excluding the example sentences that were already provided, please present **three** of the prompts you entered along with their generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e69a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"[ your answer ]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9bc15",
   "metadata": {},
   "source": [
    "### Question 3-5) Generate Text with Pretrained Model [5 points]\n",
    "\n",
    "Compare the output quality between your trained model and the pretrained model.  \n",
    "What differences do you observe? Why do you think these differences exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"[ your answer ]\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
